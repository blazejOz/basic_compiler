import re
from lexical_analysis.token_specifcation import TokenSpecification

class Lexer():
    def __init__(self, src: str):
       self.src = src
       self.tokens = []
       self.token_spec = TokenSpecification()

    def tokenize():
        pass